# Showcase Interview Phase Contract

**Created**: 2026-02-18
**Confidence Score**: 96/100
**Status**: Draft

## Problem Statement

Showcase artifacts are meant to tell the story of a real, specific case - a project the consultant actually delivered, with concrete problems, approaches, results, and lessons learned. However, the current content creation pipeline treats showcases the same as blogs and social posts: the only user input is a brief topic title and optional description before the AI begins researching and writing.

This produces generic, surface-level showcase content. The AI has no visibility into the actual case details - the client context, the specific challenges faced, the methodology applied, the measurable outcomes, or the unique lessons learned. Without this information, the research phase searches for generic industry content rather than supporting evidence for a real story, and the writing phase produces content that reads like a thought leadership article rather than a compelling case study.

The user (consultant) is the only source of truth for their showcase stories. The system needs a structured way to extract this knowledge before the automated pipeline runs.

## Goals

1. **Rich author briefs for showcases**: Replace the current 1-2 sentence topic description with a comprehensive, structured brief containing full case details (context, problem, approach, results, lessons) extracted through conversational interview
2. **Score-based interview completeness**: Implement a coverage scoring system across 5 dimensions (Case Context, Problem/Challenge, Approach/Methodology, Results/Outcomes, Lessons/Insights) that determines when the interview has gathered sufficient detail to proceed
3. **Adaptive questioning**: The interview agent leverages existing user profile data (profession, expertise, skills) to skip obvious questions and ask targeted, case-specific follow-ups
4. **Seamless pipeline integration**: The interview phase slots between topic selection and research as a new `interviewing` status, with the synthesized brief flowing into `conductDeepResearch` as an enhanced `author_brief`
5. **Persistent interview state**: Interview Q&A pairs are saved incrementally so users can abandon and resume mid-interview without losing progress

## Success Criteria

- [ ] Showcase artifacts have a new `interviewing` status between `draft` and `research`
- [ ] The AI asks one question at a time in the existing chat panel, creating a natural ping-pong conversation
- [ ] The agent tracks coverage across 5 dimensions and calculates a completeness score after each answer
- [ ] When coverage score reaches threshold (>=95%), the agent synthesizes a structured brief and presents a summary in chat
- [ ] The user can confirm the summary to proceed to research, or provide corrections
- [ ] The synthesized brief is stored as `artifacts.metadata.author_brief` and feeds into `conductDeepResearch`
- [ ] Research queries generated by `conductDeepResearch` are noticeably more targeted when fed an interview-enriched brief vs. a plain topic description
- [ ] Interview Q&A pairs persist to database incrementally (survive page refresh/browser close)
- [ ] Resuming an interrupted interview picks up where the user left off with full prior context
- [ ] Users can skip the interview for showcases with a warning about reduced content quality
- [ ] The interview flow does NOT apply to social posts or blog artifacts (existing flow unchanged)
- [ ] All existing pipeline steps (research, skeleton, writing, images) continue to work unchanged
- [ ] State machine transitions are updated in both frontend and backend types

## Scope Boundaries

### In Scope

- New `interviewing` artifact status with proper state machine transitions (`draft` -> `interviewing` -> `research`)
- Database table `artifact_interviews` to store Q&A pairs per artifact
- Interview orchestration logic in the system prompt (question generation, coverage tracking, follow-up decisions)
- `startShowcaseInterview` and `completeShowcaseInterview` AI tools for the chat flow
- Coverage scoring system with 5 dimensions scored 0-20 each (total /100)
- Adaptive question selection based on user profile data from `user_context` and `skills` tables
- Interview summary synthesis and user confirmation flow in chat
- Skip interview option with warning for showcase artifacts
- Resume interrupted interview with full prior Q&A context
- Frontend state machine, status colors, labels, and icons for `interviewing` status
- Integration with existing `conductDeepResearch` (enhanced brief replaces simple topic description)

### Out of Scope

- Changing the interview to a separate UI panel (stays in chat) - may be a future enhancement
- Applying interviews to blog or social post artifacts - showcase only for now
- Voice/audio input for interview answers - text only
- Multi-user interviews (e.g., interviewing the client) - consultant only
- Editing interview answers after completion (user can correct in the summary confirmation step)
- Analytics/reporting on interview quality or patterns

### Future Considerations

- Interview templates per showcase sub-type (product launch, transformation, advisory engagement)
- Re-interview capability to update an existing showcase with new information
- Interview-to-social-post: extracting social post angles from interview transcripts
- Rich media in interview answers (screenshots, documents, data tables)

---

*This contract was generated from brain dump input. Review and approve before proceeding to PRD generation.*
